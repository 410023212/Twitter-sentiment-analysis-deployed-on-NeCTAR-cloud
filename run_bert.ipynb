{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_bert",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fish-WY/CCCproject2-team56/blob/master/run_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz9YbaRkjjQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn80IsYbe2bf",
        "colab_type": "code",
        "outputId": "2a837e33-926d-4b27-fe4d-000e769a1292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 从Google drive 装载输入json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mount','/My Drive/NLP_data')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/mount\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reoCxtxMihxg",
        "colab_type": "code",
        "outputId": "9bd10812-7064-40ab-94c8-fa7d08808da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 指定当前的工作文件夹\n",
        "import os\n",
        "os.chdir(\"/content/mount/My Drive\") \n",
        "!pwd"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mount/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExmtQ7hKmlAd",
        "colab_type": "code",
        "outputId": "4a375bcf-aab0-4460-fc65-a6f45aa2ddcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# 初始化 TPU\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.59.22.146:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 238540411328499553),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6673683554183995757),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4849193859098477182),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 571120506542292246),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 11225175825315373857),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5286956204914458770),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 5653376955440038791),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 5859819985035958201),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 11277503855293199018),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15119320913386212703),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 8240959710031936460)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayoKIkG4nuAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import run_classifier_with_tfhub\n",
        "import tokenization\n",
        "\n",
        "# import tfhub \n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-CeyifkoD7c",
        "colab_type": "code",
        "outputId": "6ea608c9-95d4-43d6-b224-ca539738baca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 初始化 bucket （TPU 需要）\n",
        "BUCKET = '2019_bucket' #@param {type:\"string\"}\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert-tfhub/models'.format(BUCKET)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "\n",
        "BERT_MODEL = 'cased_L-24_H-1024_A-16' #@param {type:\"string\"}\n",
        "# TODO bert_hub_module option 'bert_uncased_L-24_H-1024_A-16/1'\n",
        "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://2019_bucket/bert-tfhub/models *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VHS39yqn7Bt",
        "colab_type": "code",
        "outputId": "b4a99af9-5f86-4cb0-e098-9b9f4b230b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0711 14:12:16.813023 140059163133824 deprecation_wrapper.py:119] From bert_repo/run_classifier_with_tfhub.py:151: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0711 14:12:17.499323 140059163133824 deprecation_wrapper.py:119] From bert_repo/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGIHeD9AqFOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BATCH_SIZE = 8\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "SAVE_SUMMARY_STEPS = 500\n",
        "data_dir = './'\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "        Args:\n",
        "          guid: Unique id for the example.\n",
        "          text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "          text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "          label: (Optional) string. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "class DataProcessor(object):\n",
        "    # 转换自己的 json 到 bert 接受的输入格式\n",
        "    def __init__(self):\n",
        "        self.dummy = None\n",
        "\n",
        "    def get_labels(self):\n",
        "        return ['SUPPORTS', 'REFUTES', 'NOT ENOUGH INFO']\n",
        "      \n",
        "    def get_myexamples(self,filename):\n",
        "        file_path = os.path.join(data_dir, filename + '_content.json')\n",
        "        with open(file_path, 'r') as f:\n",
        "            reader = json.loads(f.read())\n",
        "        examples = []\n",
        "        for key, value in reader.items():\n",
        "            guid = filename + '-%d' % int(key)\n",
        "            text_a = tokenization.convert_to_unicode(value['claim'])\n",
        "            text_b = ''\n",
        "            label = value['label']\n",
        "            \n",
        "            evidence_list = value['evidence']\n",
        "            for index, evidence in enumerate(evidence_list):\n",
        "                if len(evidence) > 2:\n",
        "                  text_b += evidence[2]\n",
        "            if text_b or True:\n",
        "                text_b = tokenization.convert_to_unicode(text_b)\n",
        "                examples.append(InputExample(guid=guid, text_a=text_a,text_b=text_b, label=label))\n",
        "        return examples\n",
        "\n",
        "    def get_train_examples(self):\n",
        "        return self.get_myexamples('train')\n",
        "        \n",
        "\n",
        "    def get_dev_examples(self):\n",
        "        return self.get_myexamples('devset')\n",
        "\n",
        "    def get_test_examples(self):\n",
        "        return self.get_myexamples('test')\n",
        "\n",
        "\n",
        "processor = DataProcessor()\n",
        "label_list = processor.get_labels()\n",
        "\n",
        "# Compute number of train and warmup steps from batch size\n",
        "train_examples = processor.get_train_examples()\n",
        "num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Setup TPU related config\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "NUM_TPU_CORES = 8\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "\n",
        "def get_run_config(output_dir):\n",
        "  return tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=output_dir,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zen3_VvP7V7W",
        "colab_type": "code",
        "outputId": "d64d89a6-dd60-4e55-dd02-f3da7c7e73fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Force TF Hub writes to the GS bucket we provide.\n",
        "os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR\n",
        "\n",
        "model_fn = run_classifier_with_tfhub.model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=True,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB\n",
        ")\n",
        "\n",
        "estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=True,\n",
        "  model_fn=model_fn,\n",
        "  config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE,\n",
        ")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0711 14:14:45.421996 140059163133824 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f61b85cc488>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0N5ToO67p4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_train(estimator):\n",
        "  print('Start training')\n",
        "  # We'll set sequences to be at most 128 tokens long.\n",
        "  train_features = run_classifier.convert_examples_to_features(\n",
        "      train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(train_examples)))\n",
        "  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "  train_input_fn = run_classifier.input_fn_builder(\n",
        "      features=train_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=True,\n",
        "      drop_remainder=True)\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  print('***** Finished training at {} *****'.format(datetime.datetime.now()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDGnfkrM73JI",
        "colab_type": "code",
        "outputId": "850e9c2b-d02a-45dd-c1d2-c32020806a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "model_train(estimator_from_tfhub)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0711 14:14:56.199965 140059163133824 deprecation_wrapper.py:119] From bert_repo/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Start training\n",
            "***** Started training at 2019-07-11 14:18:33.854588 *****\n",
            "  Num examples = 145449\n",
            "  Batch size = 8\n",
            "***** Finished training at 2019-07-11 14:18:35.069777 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfbB6Nns-hEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_eval(estimator):\n",
        "  # Eval the model.\n",
        "  eval_examples = processor.get_dev_examples()\n",
        "  eval_features = run_classifier.convert_examples_to_features(\n",
        "      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(eval_examples)))\n",
        "  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "\n",
        "  # Eval will be slightly WRONG on the TPU because it will truncate\n",
        "  # the last batch.\n",
        "  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
        "  eval_input_fn = run_classifier.input_fn_builder(\n",
        "      features=eval_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=True)\n",
        "  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "      print('  {} = {}'.format(key, str(result[key])))\n",
        "      writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc5u-R3K-jks",
        "colab_type": "code",
        "outputId": "79d660ec-5cc1-40fb-bee5-dd46aae25f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_eval(estimator_from_tfhub)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started evaluation at 2019-07-11 04:16:57.223078 *****\n",
            "  Num examples = 5001\n",
            "  Batch size = 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0711 04:17:10.987760 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:10.989634 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:10.991346 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:10.992946 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.000245 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.012918 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.025957 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.033711 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.039262 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.057941 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.062493 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.071695 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.076055 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.083879 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.089548 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.103361 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.108567 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.115698 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.120349 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.128980 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.132927 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.143537 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.147845 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.154006 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.158831 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.174717 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.178335 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.186274 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.191186 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.197777 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.202851 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.218404 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.223348 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.231506 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.237105 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.246076 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.250639 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.260787 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.265532 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.272935 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.277258 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.291356 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.295951 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.303699 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.308183 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.317350 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.322380 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.337279 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.342676 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.350133 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.354821 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.366607 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.371137 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.380462 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.385361 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.392128 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.396851 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.410037 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.414652 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.421780 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.426579 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.433120 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.437422 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.454274 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.458838 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.466707 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.471227 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.482285 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.488472 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.498025 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.502421 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.508549 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.513325 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.523919 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.530272 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.537309 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.542275 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.549200 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.553843 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.567501 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.572383 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.578884 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.583721 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.593199 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.600068 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.612554 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.616970 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.623386 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.628777 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.639234 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.643779 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.650974 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.655071 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.663340 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.669777 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.682435 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.687204 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.693625 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.698086 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.710953 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.715645 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.725087 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.729338 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.736564 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.741098 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.753467 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.758145 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.765246 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.769590 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.776422 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.782400 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.795731 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.800032 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.806519 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.810483 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.820459 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.826789 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.835825 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.841075 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.847055 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.852092 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.864978 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.872692 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.879646 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.885107 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.890993 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.896481 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.912238 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.916714 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.929270 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.934973 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.944145 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.949401 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.958509 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.963009 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.969531 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.974300 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.984988 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.989887 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:11.996446 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.001017 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.009690 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.014451 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.027786 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.032957 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.040143 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.045046 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.053189 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.057732 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.067005 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.072081 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.078534 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.082830 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.093621 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.097699 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.107302 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.112144 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.118182 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.122639 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.136672 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.141557 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.148651 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.153241 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.162018 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.167666 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.176770 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.181972 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.188409 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.193485 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.203805 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.208191 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.215523 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.219594 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.226755 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.232928 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.246782 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.253211 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.262485 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.266477 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.278405 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.283374 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.294112 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.300138 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.307991 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.312865 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.327768 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.332836 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.339897 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.344906 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.350948 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.357321 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.371820 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.376871 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.384181 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.389315 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.400439 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.405633 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.414870 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.419473 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.428645 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.433502 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.445596 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.450874 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.457325 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.461889 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.469350 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.476285 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.490014 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.494143 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.500409 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.505290 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.516891 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.521258 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.530025 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.533992 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.540473 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.544939 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_12/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.560952 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.567106 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.573630 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.577494 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.583696 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.588640 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.602431 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.607024 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.614052 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.618419 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.628152 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.633902 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.648232 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.655867 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.662247 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.667670 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_13/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.680774 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.685551 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.693713 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.699548 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.706079 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.712638 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.726857 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.732235 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.741241 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.745251 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.756967 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.761398 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.773618 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.778609 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.786200 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.791504 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_14/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.803601 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.808366 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.816998 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.822477 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.828691 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.834554 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.849507 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.856873 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.863559 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.868428 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.878882 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.883575 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.892983 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.898038 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.904225 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.909144 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_15/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.919751 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.924527 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.931308 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.936321 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.942267 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.947548 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.961110 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.965940 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.972709 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.977252 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.986333 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:12.991237 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.003118 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.007929 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.014896 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.019573 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_16/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.030629 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.035201 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.044639 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.049666 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.059289 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.063869 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.081207 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.086205 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.093607 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.097406 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.112641 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.119544 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.129661 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.135369 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.143314 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.148929 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_17/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.161994 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.170561 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.177656 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.182475 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.188759 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.193652 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.208013 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.212748 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.221099 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.226231 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.235277 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.240122 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.249760 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.254782 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.261640 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.266625 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_18/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.276927 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.281776 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.291122 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.296517 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.303265 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.308382 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.322192 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.328769 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.335126 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.340047 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.349024 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.354445 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.365043 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.369875 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.376379 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.381407 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_19/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.393018 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.398262 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.405542 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.411263 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.417502 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.423574 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.437621 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.441963 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.456053 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.461215 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.474837 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.478729 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.491814 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.497021 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.503919 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.508911 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_20/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.526046 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.530867 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.537588 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.541757 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.547876 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.552495 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.566525 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.570800 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.578476 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.583457 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.592013 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.596144 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.605066 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.609274 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.616549 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.621005 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_21/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.632281 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.638378 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.647414 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.652423 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.659094 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.664328 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.677979 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.682773 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.689890 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.695074 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.703735 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.708968 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.717751 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.723056 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.729126 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.734265 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_22/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.745058 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.750770 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.757551 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.762108 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.772099 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.777248 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.790953 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.795875 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.804256 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.809140 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.821043 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.827394 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.836416 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.841836 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.847873 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.853700 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_23/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.902235 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.906562 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.920051 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.924524 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.933563 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.937523 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0711 04:17:13.945972 140642818299776 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "W0711 04:17:14.397756 140642818299776 deprecation_wrapper.py:119] From bert_repo/run_classifier_with_tfhub.py:62: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0711 04:17:14.417526 140642818299776 deprecation_wrapper.py:119] From bert_repo/run_classifier_with_tfhub.py:69: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0711 04:17:14.497374 140642818299776 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3154: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0711 04:17:15.248437 140642818299776 deprecation_wrapper.py:119] From bert_repo/run_classifier_with_tfhub.py:122: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0711 04:17:15.272558 140642818299776 deprecation_wrapper.py:119] From bert_repo/run_classifier_with_tfhub.py:123: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W0711 04:17:16.561110 140642818299776 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0711 04:17:17.717540 140642818299776 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0711 04:18:28.142099 140642818299776 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:792: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Finished evaluation at 2019-07-11 04:18:54.332444 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.6264\n",
            "  eval_loss = 4.9685483\n",
            "  global_step = 54543\n",
            "  loss = 5.144504\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}